name: mae

learning_rate: 0.015

augmentations:

  train:
    
    # Random resized crop
    - _target_: torchvision.transforms.RandomResizedCrop
      size: 224
    
    # Horizontal flip
    - _target_: torchvision.transforms.RandomHorizontalFlip
      p: 1.0
    
    # Convert to tensor
    - _target_: torchvision.transforms.ToTensor

    # Normalization
    - _target_: torchvision.transforms.Normalize
      mean: ${dataset.mean}
      std: ${dataset.std}

params: ${model.vit_large}

vit_base:
  mask_ratio: 0.75
  norm_pix_loss: false
  patch_size: 16
  dim: 768
  depth: 12
  num_heads: 12
  decoder_embed_dim: 512
  decoder_depth: 8
  decoder_num_heads: 16
  mlp_ratio: 4
  norm_layer:
    _partial_: true
    _target_: torch.nn.LayerNorm
    eps: 1e-6

vit_large:
  mask_ratio: 0.75
  norm_pix_loss: false
  patch_size: 16
  dim: 1024
  depth: 24
  num_heads: 16
  decoder_embed_dim: 512
  decoder_depth: 8
  decoder_num_heads: 16
  mlp_ratio: 4
  norm_layer:
    _partial_: true
    _target_: torch.nn.LayerNorm
    eps: 1e-6
  
vit_huge:
  mask_ratio: 0.75
  norm_pix_loss: true
  patch_size: 14
  dim: 1280
  depth: 32
  num_heads: 16
  decoder_embed_dim: 512
  decoder_depth: 8
  decoder_num_heads: 16
  mlp_ratio: 4
  norm_layer:
    _partial_: true
    _target_: torch.nn.LayerNorm
    eps: 1e-6
