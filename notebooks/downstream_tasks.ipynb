{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating downstream model against pre-trained Self-Supervised models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T17:08:35.256482447Z",
     "start_time": "2023-04-24T17:08:28.225101976Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:35: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:93: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:234: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/datamodules/experience_source.py:18: UnderReviewWarning: The feature warn_missing_pkg is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  warn_missing_pkg(\"gym\")\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.models.self_supervised.simclr import SimCLREvalDataTransform\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pl_bolts.models.self_supervised import SimCLR, BYOL\n",
    "import torchvision.transforms as T\n",
    "from lightly.models import utils\n",
    "from lightly.models.modules import masked_autoencoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import plotly.express as px\n",
    "import pytorch_lightning as pl\n",
    "from time import time\n",
    "from PIL import Image\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAE(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, learning_rate=1.5e-3, mask_ratio=0.75, decoder_dim=512, decoder_layers=4, decoder_heads=16, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        vit = torchvision.models.vit_b_16(weights=None)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.patch_size = vit.patch_size\n",
    "        self.sequence_length = vit.seq_length\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_dim))\n",
    "        self.backbone = masked_autoencoder.MAEBackbone.from_vit(vit)\n",
    "        self.decoder = masked_autoencoder.MAEDecoder(\n",
    "            seq_length=vit.seq_length,\n",
    "            num_layers=decoder_layers,\n",
    "            num_heads=decoder_heads,\n",
    "            embed_input_dim=vit.hidden_dim,\n",
    "            hidden_dim=decoder_dim,\n",
    "            mlp_dim=decoder_dim * 4,\n",
    "            out_dim=vit.patch_size**2 * 3,\n",
    "            dropout=0,\n",
    "            attention_dropout=0,\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward_encoder(self, images, idx_keep=None):\n",
    "        return self.backbone.encode(images, idx_keep)\n",
    "\n",
    "    def forward_decoder(self, x_encoded, idx_keep, idx_mask):\n",
    "        # build decoder input\n",
    "        batch_size = x_encoded.shape[0]\n",
    "        x_decode = self.decoder.embed(x_encoded)\n",
    "        x_masked = utils.repeat_token(\n",
    "            self.mask_token, (batch_size, self.sequence_length)\n",
    "        )\n",
    "        x_masked = utils.set_at_index(x_masked, idx_keep, x_decode.type_as(x_masked))\n",
    "\n",
    "        # decoder forward pass\n",
    "        x_decoded = self.decoder.decode(x_masked)\n",
    "\n",
    "        # predict pixel values for masked tokens\n",
    "        x_pred = utils.get_at_index(x_decoded, idx_mask)\n",
    "        x_pred = self.decoder.predict(x_pred)\n",
    "        return x_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, _, _ = batch\n",
    "        images = images[0]  # images is a list containing only one view\n",
    "        batch_size = images.shape[0]\n",
    "        idx_keep, idx_mask = utils.random_token_mask(\n",
    "            size=(batch_size, self.sequence_length),\n",
    "            mask_ratio=self.mask_ratio,\n",
    "            device=images.device,\n",
    "        )\n",
    "        x_encoded = self.forward_encoder(images, idx_keep)\n",
    "        x_pred = self.forward_decoder(x_encoded, idx_keep, idx_mask)\n",
    "\n",
    "        # get image patches for masked tokens\n",
    "        patches = utils.patchify(images, self.patch_size)\n",
    "        # must adjust idx_mask for missing class token\n",
    "        target = utils.get_at_index(patches, idx_mask - 1)\n",
    "\n",
    "        loss = self.criterion(x_pred, target)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, _, _ = batch\n",
    "        images = images[0]  # images is a list containing only one view\n",
    "        batch_size = images.shape[0]\n",
    "        idx_keep, idx_mask = utils.random_token_mask(\n",
    "            size=(batch_size, self.sequence_length),\n",
    "            mask_ratio=self.mask_ratio,\n",
    "            device=images.device,\n",
    "        )\n",
    "        x_encoded = self.forward_encoder(images, idx_keep)\n",
    "        x_pred = self.forward_decoder(x_encoded, idx_keep, idx_mask)\n",
    "\n",
    "        # get image patches for masked tokens\n",
    "        patches = utils.patchify(images, self.patch_size)\n",
    "        # must adjust idx_mask for missing class token\n",
    "        target = utils.get_at_index(patches, idx_mask - 1)\n",
    "\n",
    "        loss = self.criterion(x_pred, target)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, betas=(0.9, 0.95))\n",
    "        return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_checkpoint(selected_model, choice=None):\n",
    "    logs_dir = os.path.join(\n",
    "        '/home/woody/iwfa/iwfa028h/dev/faps/data/trained_models/',\n",
    "        selected_model,\n",
    "        'lightning_logs'\n",
    "    )\n",
    "\n",
    "    best_version = max(\n",
    "        map(\n",
    "            lambda x: int(x.replace('version_', '')) if 'version' in x else 0,\n",
    "            os.listdir(logs_dir)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    version_dir = os.path.join(logs_dir, f'version_{best_version if not choice else choice}', 'checkpoints')\n",
    "    best_checkpoint = os.path.join(version_dir, os.listdir(version_dir)[0])\n",
    "    print('LATEST CHECKPOINT', best_checkpoint)\n",
    "\n",
    "    return best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICDARDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_filepath, root_dir, transforms=None, convert_rgb=True):\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        self.convert_rgb = convert_rgb\n",
    "        \n",
    "        df = pd.read_csv(csv_filepath, sep=';')\n",
    "        df['img_path'] = root_dir + os.sep + df.FILENAME\n",
    "        self.data = df.loc[\n",
    "            (df.img_path.map(os.path.exists)) &\n",
    "            (df.img_path.str.contains(''))\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.data.loc[idx, 'img_path']\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "        except Exception as ex:\n",
    "            return None\n",
    "\n",
    "        if self.convert_rgb:\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, self.data.loc[idx, 'SCRIPT_TYPE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_checkpoint(model_name, choice=None, **model_kwargs):\n",
    "    \n",
    "    checkpoint = get_best_checkpoint(model_name, choice)\n",
    "    print(model_kwargs)\n",
    "    \n",
    "    if model_name == 'SimCLR':\n",
    "        model = SimCLR.load_from_checkpoint(checkpoint, strict=False, **model_kwargs)\n",
    "        return model.encoder\n",
    "    elif model_name == 'BYOL':\n",
    "        model = BYOL.load_from_checkpoint(checkpoint, strict=False, **model_kwargs)\n",
    "    elif model_name == 'MAE':\n",
    "        model = MAE.load_from_checkpoint(checkpoint, strict=False, **model_kwargs)\n",
    "        return model.backbone\n",
    "    elif model_name in ['SimCLRDownstream', 'BYOLDownstream', 'DownstreamClassifier']:\n",
    "        model = DownstreamClassifier.load_from_checkpoint(checkpoint, strict=False, **model_kwargs)\n",
    "        return model\n",
    "    else:\n",
    "        model = SimCLR.load_from_checkpoint(checkpoint, strict=False)\n",
    "        return embeddings_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_factory(dataset_name, root_dir, label_filepath, transforms, mode, batch_size, collate_fn=None, num_cpus=None):\n",
    "\n",
    "    if dataset_name.lower() == 'icdar':\n",
    "        dataset = ICDARDataset(label_filepath, root_dir, transforms=transforms(), convert_rgb=True)\n",
    "    else:\n",
    "        raise NotImplementedError(f'Dataset {dataset_name} is not implemented')\n",
    "\n",
    "    total_count = len(dataset)\n",
    "    train_count = int(0.7 * total_count)\n",
    "    val_count = int(0.1 * total_count)\n",
    "    test_count = total_count - train_count - val_count\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset,\n",
    "        (train_count, val_count, test_count),\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "\n",
    "    if mode in 'train':\n",
    "        return {\n",
    "            'train': DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                drop_last=True,\n",
    "                pin_memory=True,\n",
    "                persistent_workers=True,\n",
    "                num_workers=num_cpus or os.cpu_count(),\n",
    "                collate_fn=collate_fn() if collate_fn else None\n",
    "            ),\n",
    "            'val': DataLoader(\n",
    "                val_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                drop_last=False,\n",
    "                pin_memory=True,\n",
    "                persistent_workers=True,\n",
    "                num_workers=num_cpus or os.cpu_count(),\n",
    "                collate_fn=collate_fn() if collate_fn else None\n",
    "            )\n",
    "        }\n",
    "    elif mode == 'test':\n",
    "        return {\n",
    "            'test': DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                drop_last=False,\n",
    "                pin_memory=True,\n",
    "                persistent_workers=True,\n",
    "                num_workers=num_cpus or os.cpu_count(),\n",
    "                collate_fn=collate_fn() if collate_fn else None\n",
    "            )\n",
    "        }\n",
    "    else:\n",
    "        raise KeyError(f'Unknown mode: {mode}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = os.path.join(\n",
    "#     '/home/woody/iwfa/iwfa028h/dev/faps', 'data', 'ICDAR2017_CLaMM_Training'\n",
    "# )\n",
    "\n",
    "# train_dataloaders = data_factory(\n",
    "#     dataset_name='icdar',\n",
    "#     root_dir=root_dir,\n",
    "#     label_filepath=os.path.join(root_dir, '@ICDAR2017_CLaMM_Training.csv'),\n",
    "#     transforms=SimCLREvalDataTransform,\n",
    "#     mode='train',\n",
    "#     batch_size=256,\n",
    "#     num_cpus=4\n",
    "# )\n",
    "\n",
    "# test_dataloaders = data_factory(\n",
    "#     dataset_name='icdar',\n",
    "#     root_dir=root_dir, \n",
    "#     label_filepath=os.path.join(root_dir, '@ICDAR2017_CLaMM_Training.csv'),\n",
    "#     transforms=SimCLREvalDataTransform,\n",
    "#     mode='test',\n",
    "#     batch_size=256,\n",
    "#     num_cpus=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(model, data_loader, num_feats, batch_size, num_samples, perplexity=25):\n",
    "    num_samples = len(data_loader) if not num_samples else num_samples\n",
    "    feats = np.array([]).reshape((0, num_feats))\n",
    "    labels = np.array([])\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    processed_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for (x1, x2, _), label in data_loader:\n",
    "            if processed_samples >= num_samples:\n",
    "                break\n",
    "            x1 = x1.squeeze().cuda()\n",
    "            out = model(x1)\n",
    "            out = out[-1].detach().cpu().numpy()\n",
    "            print(out.shape)\n",
    "            feats = np.append(feats, out, axis=0)\n",
    "            labels = np.append(labels, label, axis=0)\n",
    "            processed_samples += batch_size\n",
    "\n",
    "    tsne = TSNE(n_components=3, perplexity=perplexity, init='pca')\n",
    "    x_feats = tsne.fit_transform(feats)\n",
    "\n",
    "    dim_red_df = pd.DataFrame(x_feats)\n",
    "    dim_red_df['labels'] = pd.Categorical(labels)\n",
    "    fig = px.scatter_3d(dim_red_df, x=0, y=1, z=2, color='labels', size_max=5)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_embeddings(model, dataloader):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        x1, x2, _ = images\n",
    "        x1 = x1.to('cuda')\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(x1)[-1].detach().cpu().numpy()\n",
    "        X.append(embeddings)\n",
    "        y.append(labels.numpy())\n",
    "        \n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_embeddings():\n",
    "    \n",
    "    simclr_encoder = load_best_checkpoint('SimCLR')\n",
    "    simclr_encoder.eval()\n",
    "    simclr_encoder.cuda()\n",
    "    \n",
    "    X_train, y_train = generate_from_embeddings(simclr_encoder, train_dataloaders.get('train'))\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "    print(knn)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    X_test, y_test = generate_from_embeddings(simclr_encoder, test_dataloaders.get('test'))\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return knn\n",
    "    \n",
    "#     plot_features(simclr_encoder, dataloaders.get('train'), 2048, 256, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownstreamClassifier(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, base_model_name='SimCLR', base_model_version=None, features=2048, num_classes=13, learning_rate=1e-2):\n",
    "        print(base_model_name, features, num_classes)\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "                \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.base_model = load_best_checkpoint(base_model_name, choice=base_model_version, num_classes=num_classes)\n",
    "        self.base_model.eval()\n",
    "\n",
    "        self.classifier = nn.Linear(features, num_classes)\n",
    "        \n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes).to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.base_model(x)\n",
    "            if isinstance(x, list):\n",
    "                x = x[-1]\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x1, x2, _), label = batch\n",
    "        y_hat = self(x1)\n",
    "        loss = self.loss_fn(y_hat, label)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        (x1, x2, _), label = batch\n",
    "        y_hat = self(x1)\n",
    "        loss = self.loss_fn(y_hat, label)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        (x1, x2, _), label = batch\n",
    "        y_hat = self(x1)\n",
    "        acc = self.accuracy_fn(y_hat, label)\n",
    "        self.log('test_acc', acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_downstream_model(model_name, downstream_model_name, feats=2048, max_epochs=10):\n",
    "    \n",
    "    root_dir = os.path.join(\n",
    "        '/home/woody/iwfa/iwfa028h/dev/faps', 'data', 'ICDAR2017_CLaMM_task1_task3'\n",
    "    )\n",
    "    dataloaders = data_factory(\n",
    "        dataset_name='icdar',\n",
    "        root_dir=root_dir, \n",
    "        label_filepath=os.path.join(root_dir, '@ICDAR2017_CLaMM_task1_task3.csv'),\n",
    "        transforms=SimCLREvalDataTransform,\n",
    "        mode='train',\n",
    "        batch_size=64,\n",
    "        num_cpus=8\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.abspath(os.path.join(root_dir, '..', 'trained_models', downstream_model_name)),\n",
    "        accelerator='gpu',\n",
    "        devices=-1,\n",
    "        max_epochs=max_epochs,\n",
    "        enable_progress_bar=True,\n",
    "        precision=16,\n",
    "        callbacks=[\n",
    "            pl.callbacks.ModelCheckpoint(mode=\"min\", monitor=\"val_loss\"),\n",
    "            pl.callbacks.RichProgressBar()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    downstream_classifier = DownstreamClassifier(model_name, '598468', feats, 13)\n",
    "    \n",
    "    trainer.fit(downstream_classifier, dataloaders.get('train'), dataloaders.get('val'))\n",
    "    \n",
    "    return downstream_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCLR 2048 13\n",
      "LATEST CHECKPOINT /home/woody/iwfa/iwfa028h/dev/faps/data/trained_models/SimCLR/lightning_logs/version_598468/checkpoints/epoch=200-step=7638.ckpt\n",
      "{'num_classes': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:224: UnderReviewWarning: The feature SimCLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  obj = cls(**_cls_kwargs)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/simclr/simclr_module.py:138: UnderReviewWarning: The feature resnet50 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return backbone(first_conv=self.first_conv, maxpool1=self.maxpool1, return_all_feature_maps=False)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:321: UnderReviewWarning: The feature _resnet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return _resnet(\"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:281: UnderReviewWarning: The feature ResNet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  model = ResNet(block, layers, **kwargs)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:223: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  conv1x1(self.inplanes, planes * block.expansion, stride),\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:229: UnderReviewWarning: The feature Bottleneck is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  block(\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:110: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/simclr/simclr_module.py:126: UnderReviewWarning: The feature Projection is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.projection = Projection(input_dim=self.hidden_mlp, hidden_dim=self.hidden_mlp, output_dim=self.feat_dim)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model  │ ResNet             │ 25.6 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ classifier  │ Linear             │ 26.6 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ loss_fn     │ CrossEntropyLoss   │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ accuracy_fn │ MulticlassAccuracy │      0 │\n",
       "└───┴─────────────┴────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName       \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model  │ ResNet             │ 25.6 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ classifier  │ Linear             │ 26.6 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ loss_fn     │ CrossEntropyLoss   │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ accuracy_fn │ MulticlassAccuracy │      0 │\n",
       "└───┴─────────────┴────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 25.6 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 25.6 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 51                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 25.6 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 25.6 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 51                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6520d932eba54289a3505572bd33e409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: \n",
       "UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current\n",
       "system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker \n",
       "creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential \n",
       "slowness/freeze if necessary.\n",
       "  warnings.warn(_create_warning_msg(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: \n",
       "UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current\n",
       "system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker \n",
       "creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential \n",
       "slowness/freeze if necessary.\n",
       "  warnings.warn(_create_warning_msg(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1555: \n",
       "PossibleUserWarning: The number of training batches (21) is smaller than the logging interval \n",
       "Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training \n",
       "epoch.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1555: \n",
       "PossibleUserWarning: The number of training batches (21) is smaller than the logging interval \n",
       "Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training \n",
       "epoch.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "downstream_model = train_downstream_model('SimCLR', 'SimCLRDownstream', 2048, 50)\n",
    "# downstream_model = train_downstream_model('MAE', 'MAEDownstream', 768, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_downstream_model(base_model_name, model_name):\n",
    "    \n",
    "    root_dir = os.path.join(\n",
    "        '/home/woody/iwfa/iwfa028h/dev/faps', 'data', 'ICDAR2017_CLaMM_task1_task3'\n",
    "    )\n",
    "    dataloaders = data_factory(\n",
    "        dataset_name='icdar',\n",
    "        root_dir=root_dir, \n",
    "        label_filepath=os.path.join(root_dir, '@ICDAR2017_CLaMM_task1_task3.csv'),\n",
    "        transforms=SimCLREvalDataTransform,\n",
    "        mode='test',\n",
    "        batch_size=64,\n",
    "        num_cpus=8\n",
    "    )    \n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        accelerator='gpu',\n",
    "        devices=-1,\n",
    "        max_epochs=1,\n",
    "        enable_progress_bar=True,\n",
    "        precision=16,\n",
    "        enable_checkpointing=False,\n",
    "        callbacks=[pl.callbacks.RichProgressBar()]\n",
    "    )\n",
    "    \n",
    "    downstream_classifier = load_best_checkpoint(\n",
    "        model_name,\n",
    "#         choice='595299',\n",
    "        base_model_name=base_model_name,\n",
    "        base_model_version='598468',\n",
    "        features=2048,\n",
    "        num_classes=13,\n",
    "    )\n",
    "    \n",
    "    trainer.test(downstream_classifier, dataloaders.get('test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATEST CHECKPOINT /home/woody/iwfa/iwfa028h/dev/faps/data/trained_models/SimCLRDownstream/lightning_logs/version_597396/checkpoints/epoch=11-step=252.ckpt\n",
      "{'base_model_name': 'SimCLR', 'base_model_version': '598468', 'features': 2048, 'num_classes': 13}\n",
      "SimCLR 2048 13\n",
      "LATEST CHECKPOINT /home/woody/iwfa/iwfa028h/dev/faps/data/trained_models/SimCLR/lightning_logs/version_598468/checkpoints/epoch=200-step=7638.ckpt\n",
      "{'num_classes': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:224: UnderReviewWarning: The feature SimCLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  obj = cls(**_cls_kwargs)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/simclr/simclr_module.py:138: UnderReviewWarning: The feature resnet50 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return backbone(first_conv=self.first_conv, maxpool1=self.maxpool1, return_all_feature_maps=False)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:321: UnderReviewWarning: The feature _resnet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return _resnet(\"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:281: UnderReviewWarning: The feature ResNet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  model = ResNet(block, layers, **kwargs)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:223: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  conv1x1(self.inplanes, planes * block.expansion, stride),\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:229: UnderReviewWarning: The feature Bottleneck is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  block(\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/resnets.py:110: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
      "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/pl_bolts/models/self_supervised/simclr/simclr_module.py:126: UnderReviewWarning: The feature Projection is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.projection = Projection(input_dim=self.hidden_mlp, hidden_dim=self.hidden_mlp, output_dim=self.feat_dim)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e66ee56c104553981874c5ac4de562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: \n",
       "UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current\n",
       "system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker \n",
       "creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential \n",
       "slowness/freeze if necessary.\n",
       "  warnings.warn(_create_warning_msg(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/hpc/iwfa/iwfa028h/.conda/envs/lme/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: \n",
       "UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current\n",
       "system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker \n",
       "creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential \n",
       "slowness/freeze if necessary.\n",
       "  warnings.warn(_create_warning_msg(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3640897870063782     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3640897870063782    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_downstream_model('SimCLR', 'SimCLRDownstream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lme",
   "language": "python",
   "name": "lme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
